{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":6799,"databundleVersionId":4225553,"sourceType":"competition"},{"sourceId":10121862,"sourceType":"datasetVersion","datasetId":6245757},{"sourceId":193397,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":164945,"modelId":187267},{"sourceId":193967,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":165421,"modelId":187743}],"dockerImageVersionId":30805,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport glob\nimport time\nimport numpy as np\nfrom PIL import Image\nfrom pathlib import Path\nfrom tqdm.notebook import tqdm\nimport matplotlib.pyplot as plt\nfrom skimage.color import rgb2lab, lab2rgb\nPath.ls = lambda x: list(x.iterdir())\n\nimport torch\nfrom torch import nn, optim\nfrom torchvision import transforms\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision.utils import make_grid\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device:\", device)","metadata":{"_uuid":"091169ae-d3ff-465b-b1cf-59519df29188","_cell_guid":"ad448c10-2da6-438e-a380-cf31fb52744a","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-12-09T17:56:39.810487Z","iopub.execute_input":"2024-12-09T17:56:39.811222Z","iopub.status.idle":"2024-12-09T17:56:39.817383Z","shell.execute_reply.started":"2024-12-09T17:56:39.811191Z","shell.execute_reply":"2024-12-09T17:56:39.816517Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from fastai.vision.learner import create_body\nfrom torchvision.models.resnet import resnet18\nfrom fastai.vision.models.unet import DynamicUnet","metadata":{"_uuid":"b99b82ff-14e0-4207-9d37-4a07dcdaa125","_cell_guid":"5c3bbd04-f43c-44ac-a15a-738cab0f8962","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-12-09T17:56:40.243420Z","iopub.execute_input":"2024-12-09T17:56:40.243736Z","iopub.status.idle":"2024-12-09T17:56:40.247929Z","shell.execute_reply.started":"2024-12-09T17:56:40.243711Z","shell.execute_reply":"2024-12-09T17:56:40.246951Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport glob\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nfrom sklearn.model_selection import train_test_split\n\n# Define the path to the training data\ncolor_path = '/kaggle/input/imagenet-object-localization-challenge/ILSVRC/Data/CLS-LOC/train'\n\n# Get all class directories\nclass_dirs = [d for d in os.listdir(color_path) if os.path.isdir(os.path.join(color_path, d))]\n\nmax_images = 10000\nall_images = []\nnp.random.seed(100)\n\n# Gather up to 1000 images total\nfor class_dir in class_dirs:\n    if len(all_images) >= max_images:\n        break\n    class_path_pattern = os.path.join(color_path, class_dir, '*.JPEG')\n    class_images = glob.glob(class_path_pattern)\n    np.random.shuffle(class_images)  # Shuffle to get a random sample from this class\n    needed = max_images - len(all_images)\n    to_add = class_images[:needed]\n    all_images.extend(to_add)\n\nprint(\"Total images collected:\", len(all_images))\n\n# Split into training and validation sets (80% train, 20% val)\ntrain_paths, val_paths = train_test_split(all_images, test_size=0.2, random_state=123)\n\nprint(\"Total training images:\", len(train_paths))\nprint(\"Total validation images:\", len(val_paths))\n\n# Display a few training images\n_, axes = plt.subplots(4, 4, figsize=(12, 12))\nfor ax, img_path in zip(axes.flatten(), train_paths[:16]):\n    img = Image.open(img_path)\n    ax.imshow(img)\n    ax.axis(\"off\")\nplt.tight_layout()\nplt.show()","metadata":{"_uuid":"98a52e82-efac-46e6-8c51-5f626c12b5a6","_cell_guid":"fe889e3a-1c05-41e9-a776-d7618fafc6f1","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-12-09T17:56:41.503710Z","iopub.execute_input":"2024-12-09T17:56:41.504424Z","iopub.status.idle":"2024-12-09T17:56:43.512665Z","shell.execute_reply.started":"2024-12-09T17:56:41.504390Z","shell.execute_reply":"2024-12-09T17:56:43.511130Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"SIZE = 256\n\nclass ColorizationDataset(Dataset):\n    def __init__(self, paths, split='train'):\n        if split == 'train':\n            self.transforms = transforms.Compose([\n                transforms.Resize((SIZE, SIZE), Image.BICUBIC),\n                transforms.RandomHorizontalFlip(),\n            ])\n        else:\n            self.transforms = transforms.Resize((SIZE, SIZE), Image.BICUBIC)\n        \n        self.split = split\n        self.size = SIZE\n        self.paths = paths\n    \n    def __getitem__(self, idx):\n        img = Image.open(self.paths[idx]).convert(\"RGB\")\n        img = self.transforms(img)\n        img = np.array(img)\n        img_lab = rgb2lab(img).astype(\"float32\")\n        img_lab = transforms.ToTensor()(img_lab)\n        L = img_lab[[0], ...] / 50. - 1.\n        ab = img_lab[[1, 2], ...] / 110.\n        return {'L': L, 'ab': ab}\n    \n    def __len__(self):\n        return len(self.paths)\n\ndef make_dataloaders(paths, split='train', batch_size=16, n_workers=4, pin_memory=True):\n    dataset = ColorizationDataset(paths, split=split)\n    dataloader = DataLoader(dataset, batch_size=batch_size, \n                            num_workers=n_workers, pin_memory=pin_memory, shuffle=(split=='train'))\n    return dataloader\n\ntrain_dl = make_dataloaders(train_paths, split='train', batch_size=16)\nval_dl = make_dataloaders(val_paths, split='val', batch_size=16)\n\ndata = next(iter(train_dl))\nLs, abs_ = data['L'], data['ab']\nprint(\"Train batch shapes:\", Ls.shape, abs_.shape)\nprint(\"Number of batches:\", len(train_dl), \"train,\", len(val_dl), \"val\")","metadata":{"_uuid":"5c0f7465-572b-4112-a78f-e3d9bff87ae1","_cell_guid":"ef301433-f5e4-4df7-97e0-0a097f89a1ec","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-12-09T17:56:43.514605Z","iopub.execute_input":"2024-12-09T17:56:43.514897Z","iopub.status.idle":"2024-12-09T17:56:44.506646Z","shell.execute_reply.started":"2024-12-09T17:56:43.514870Z","shell.execute_reply":"2024-12-09T17:56:44.505541Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class UnetBlock(nn.Module):\n    def __init__(self, nf, ni, submodule=None, input_c=None, dropout=False,\n                 innermost=False, outermost=False):\n        super().__init__()\n        self.outermost = outermost\n        if input_c is None: input_c = nf\n        downconv = nn.Conv2d(input_c, ni, kernel_size=4,\n                             stride=2, padding=1, bias=False)\n        downrelu = nn.LeakyReLU(0.2, True)\n        downnorm = nn.BatchNorm2d(ni)\n        uprelu = nn.ReLU(True)\n        upnorm = nn.BatchNorm2d(nf)\n        \n        if outermost:\n            upconv = nn.ConvTranspose2d(ni * 2, nf, kernel_size=4,\n                                        stride=2, padding=1)\n            down = [downconv]\n            up = [uprelu, upconv, nn.Tanh()]\n            model = down + [submodule] + up\n        elif innermost:\n            upconv = nn.ConvTranspose2d(ni, nf, kernel_size=4,\n                                        stride=2, padding=1, bias=False)\n            down = [downrelu, downconv]\n            up = [uprelu, upconv, upnorm]\n            model = down + up\n        else:\n            upconv = nn.ConvTranspose2d(ni * 2, nf, kernel_size=4,\n                                        stride=2, padding=1, bias=False)\n            down = [downrelu, downconv, downnorm]\n            up = [uprelu, upconv, upnorm]\n            if dropout: up += [nn.Dropout(0.5)]\n            model = down + [submodule] + up\n        self.model = nn.Sequential(*model)\n    \n    def forward(self, x):\n        if self.outermost:\n            return self.model(x)\n        else:\n            return torch.cat([x, self.model(x)], 1)\n\nclass Unet(nn.Module):\n    def __init__(self, input_c=1, output_c=2, n_down=8, num_filters=64):\n        super().__init__()\n        unet_block = UnetBlock(num_filters * 8, num_filters * 8, innermost=True)\n        for _ in range(n_down - 5):\n            unet_block = UnetBlock(num_filters * 8, num_filters * 8, submodule=unet_block, dropout=True)\n        out_filters = num_filters * 8\n        for _ in range(3):\n            unet_block = UnetBlock(out_filters // 2, out_filters, submodule=unet_block)\n            out_filters //= 2\n        self.model = UnetBlock(output_c, out_filters, input_c=input_c, submodule=unet_block, outermost=True)\n    \n    def forward(self, x):\n        return self.model(x)\n\nclass PatchDiscriminator(nn.Module):\n    def __init__(self, input_c, num_filters=64, n_down=3):\n        super().__init__()\n        model = [self.get_layers(input_c, num_filters, norm=False)]\n        model += [self.get_layers(num_filters * 2 ** i, num_filters * 2 ** (i + 1), s=1 if i == (n_down-1) else 2) \n                  for i in range(n_down)]\n        model += [self.get_layers(num_filters * 2 ** n_down, 1, s=1, norm=False, act=False)]\n        self.model = nn.Sequential(*model)\n        \n    def get_layers(self, ni, nf, k=4, s=2, p=1, norm=True, act=True):\n        layers = [nn.Conv2d(ni, nf, k, s, p, bias=not norm)]\n        if norm: layers += [nn.BatchNorm2d(nf)]\n        if act: layers += [nn.LeakyReLU(0.2, True)]\n        return nn.Sequential(*layers)\n    \n    def forward(self, x):\n        return self.model(x)","metadata":{"_uuid":"527250bf-4b64-4b1c-b217-a1c6f590e5d3","_cell_guid":"9b24ba98-b0ad-4530-9e5c-717678194a5f","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-12-09T17:56:44.509332Z","iopub.execute_input":"2024-12-09T17:56:44.509777Z","iopub.status.idle":"2024-12-09T17:56:44.526001Z","shell.execute_reply.started":"2024-12-09T17:56:44.509729Z","shell.execute_reply":"2024-12-09T17:56:44.525114Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class GANLoss(nn.Module):\n    def __init__(self, gan_mode='vanilla', real_label=1.0, fake_label=0.0):\n        super().__init__()\n        self.register_buffer('real_label', torch.tensor(real_label))\n        self.register_buffer('fake_label', torch.tensor(fake_label))\n        if gan_mode == 'vanilla':\n            self.loss = nn.BCEWithLogitsLoss()\n        elif gan_mode == 'lsgan':\n            self.loss = nn.MSELoss()\n    \n    def get_labels(self, preds, target_is_real):\n        if target_is_real:\n            labels = self.real_label\n        else:\n            labels = self.fake_label\n        return labels.expand_as(preds)\n    \n    def forward(self, preds, target_is_real):\n        labels = self.get_labels(preds, target_is_real)\n        loss = self.loss(preds, labels)\n        return loss\n\ndef init_weights(net, init='norm', gain=0.02):\n    def init_func(m):\n        classname = m.__class__.__name__\n        if hasattr(m, 'weight') and 'Conv' in classname:\n            if init == 'norm':\n                nn.init.normal_(m.weight.data, mean=0.0, std=gain)\n            elif init == 'xavier':\n                nn.init.xavier_normal_(m.weight.data, gain=gain)\n            elif init == 'kaiming':\n                nn.init.kaiming_normal_(m.weight.data, a=0, mode='fan_in')\n            \n            if hasattr(m, 'bias') and m.bias is not None:\n                nn.init.constant_(m.bias.data, 0.0)\n        elif 'BatchNorm2d' in classname:\n            nn.init.normal_(m.weight.data, 1., gain)\n            nn.init.constant_(m.bias.data, 0.)\n            \n    net.apply(init_func)\n    print(f\"model initialized with {init} initialization\")\n    return net\n\ndef init_model(model, device):\n    model = model.to(device)\n    model = init_weights(model)\n    return model\n\nclass AverageMeter:\n    def __init__(self):\n        self.reset()\n        \n    def reset(self):\n        self.count, self.avg, self.sum = [0.] * 3\n    \n    def update(self, val, count=1):\n        self.count += count\n        self.sum += count * val\n        self.avg = self.sum / self.count\n\ndef create_loss_meters():\n    loss_D_fake = AverageMeter()\n    loss_D_real = AverageMeter()\n    loss_D = AverageMeter()\n    loss_G_GAN = AverageMeter()\n    loss_G_L1 = AverageMeter()\n    loss_G = AverageMeter()\n    \n    return {'loss_D_fake': loss_D_fake,\n            'loss_D_real': loss_D_real,\n            'loss_D': loss_D,\n            'loss_G_GAN': loss_G_GAN,\n            'loss_G_L1': loss_G_L1,\n            'loss_G': loss_G}\n\ndef update_losses(model, loss_meter_dict, count):\n    for loss_name, loss_meter in loss_meter_dict.items():\n        loss = getattr(model, loss_name)\n        loss_meter.update(loss.item(), count=count)","metadata":{"_uuid":"e9c5646b-915f-49ca-915b-a4957a8fbf2b","_cell_guid":"5ed7ba45-a1b2-4e12-939f-0f713bb51dea","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-12-09T17:56:44.527336Z","iopub.execute_input":"2024-12-09T17:56:44.527632Z","iopub.status.idle":"2024-12-09T17:56:44.542279Z","shell.execute_reply.started":"2024-12-09T17:56:44.527593Z","shell.execute_reply":"2024-12-09T17:56:44.541201Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def lab_to_rgb(L, ab):\n    L = (L + 1.) * 50.\n    ab = ab * 110.\n    Lab = torch.cat([L, ab], dim=1).permute(0, 2, 3, 1).cpu().numpy()\n    rgb_imgs = []\n    for img in Lab:\n        img_rgb = lab2rgb(img)\n        rgb_imgs.append(img_rgb)\n    return np.stack(rgb_imgs, axis=0)\n    \ndef visualize(model, data, save=True):\n    model.net_G.eval()\n    with torch.no_grad():\n        model.setup_input(data)\n        model.forward()\n    model.net_G.train()\n    fake_color = model.fake_color.detach()\n    real_color = model.ab\n    L = model.L\n    fake_imgs = lab_to_rgb(L, fake_color)\n    real_imgs = lab_to_rgb(L, real_color)\n    fig = plt.figure(figsize=(15, 12))  # Adjusted height for row titles\n    rows, cols = 3, 5  # 3 rows (Grayscale, Model generated, Actual), up to 5 columns\n\n    # Add row titles\n    plt.subplot(rows, cols, 1).set_title(\"Grayscale Image\", fontsize=16, loc='left')\n    plt.subplot(rows, cols, cols + 1).set_title(\"Model Generated Image\", fontsize=16, loc='left')\n    plt.subplot(rows, cols, 2 * cols + 1).set_title(\"Actual Image\", fontsize=16, loc='left')\n\n    for i in range(min(5, L.size(0))):\n        # Grayscale Image (Row 1)\n        ax = plt.subplot(rows, cols, i + 1)\n        ax.imshow(L[i][0].cpu(), cmap='gray')\n        ax.axis(\"off\")\n\n        # Model Generated Image (Row 2)\n        ax = plt.subplot(rows, cols, i + 1 + cols)\n        ax.imshow(fake_imgs[i])\n        ax.axis(\"off\")\n\n        # Actual Image (Row 3)\n        ax = plt.subplot(rows, cols, i + 1 + 2 * cols)\n        ax.imshow(real_imgs[i])\n        ax.axis(\"off\")\n\n    plt.tight_layout()\n    plt.show()\n    if save:\n        fig.savefig(f\"images_new/colorization_{time.time()}.png\")\n\ndef log_results(loss_meter_dict, log_file, epoch, iteration):\n    \"\"\"\n    Log the training results to a CSV file and print them to the console.\n    \"\"\"\n    with open(log_file, mode='a', newline='') as file:\n        writer = csv.writer(file)\n        for loss_name, loss_meter in loss_meter_dict.items():\n            print(f\"{loss_name}: {loss_meter.avg:.5f}\")  # Print to console\n            # Append the results to the CSV file\n            writer.writerow([epoch, iteration, loss_name, loss_meter.avg])","metadata":{"_uuid":"9df081ec-485c-4daa-b2b1-99e9374c2ecf","_cell_guid":"75c2522b-e21c-41af-b8a1-59849804ce4c","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-12-09T17:56:44.543942Z","iopub.execute_input":"2024-12-09T17:56:44.544210Z","iopub.status.idle":"2024-12-09T17:56:44.558289Z","shell.execute_reply.started":"2024-12-09T17:56:44.544185Z","shell.execute_reply":"2024-12-09T17:56:44.557450Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class MainModel(nn.Module):\n    def __init__(self, net_G=None, lr_G=2e-4, lr_D=2e-4, \n                 beta1=0.5, beta2=0.999, lambda_L1=100.):\n        super().__init__()\n        \n        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n        self.lambda_L1 = lambda_L1\n        \n        if net_G is None:\n            self.net_G = init_model(Unet(input_c=1, output_c=2, n_down=8, num_filters=64), self.device)\n        else:\n            self.net_G = net_G.to(self.device)\n        self.net_D = init_model(PatchDiscriminator(input_c=3, n_down=3, num_filters=64), self.device)\n        self.GANcriterion = GANLoss(gan_mode='vanilla').to(self.device)\n        self.L1criterion = nn.L1Loss()\n        self.opt_G = optim.Adam(self.net_G.parameters(), lr=lr_G, betas=(beta1, beta2))\n        self.opt_D = optim.Adam(self.net_D.parameters(), lr=lr_D, betas=(beta1, beta2))\n    \n    def set_requires_grad(self, model, requires_grad=True):\n        for p in model.parameters():\n            p.requires_grad = requires_grad\n        \n    def setup_input(self, data):\n        self.L = data['L'].to(self.device)\n        self.ab = data['ab'].to(self.device)\n        \n    def forward(self):\n        self.fake_color = self.net_G(self.L)\n    \n    def backward_D(self):\n        fake_image = torch.cat([self.L, self.fake_color], dim=1)\n        fake_preds = self.net_D(fake_image.detach())\n        self.loss_D_fake = self.GANcriterion(fake_preds, False)\n        real_image = torch.cat([self.L, self.ab], dim=1)\n        real_preds = self.net_D(real_image)\n        self.loss_D_real = self.GANcriterion(real_preds, True)\n        self.loss_D = (self.loss_D_fake + self.loss_D_real) * 0.5\n        self.loss_D.backward()\n    \n    def backward_G(self):\n        fake_image = torch.cat([self.L, self.fake_color], dim=1)\n        fake_preds = self.net_D(fake_image)\n        self.loss_G_GAN = self.GANcriterion(fake_preds, True)\n        self.loss_G_L1 = self.L1criterion(self.fake_color, self.ab) * self.lambda_L1\n        self.loss_G = self.loss_G_GAN + self.loss_G_L1\n        self.loss_G.backward()\n    \n    def optimize(self):\n        self.forward()\n        self.net_D.train()\n        self.set_requires_grad(self.net_D, True)\n        self.opt_D.zero_grad()\n        self.backward_D()\n        self.opt_D.step()\n        \n        self.net_G.train()\n        self.set_requires_grad(self.net_D, False)\n        self.opt_G.zero_grad()\n        self.backward_G()\n        self.opt_G.step()","metadata":{"_uuid":"f73ae1fe-7ce7-4f53-8768-d5276c348f54","_cell_guid":"76820d8b-924f-44df-954b-c3f9c7743324","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-12-09T17:56:44.559209Z","iopub.execute_input":"2024-12-09T17:56:44.559516Z","iopub.status.idle":"2024-12-09T17:56:44.575822Z","shell.execute_reply.started":"2024-12-09T17:56:44.559490Z","shell.execute_reply":"2024-12-09T17:56:44.575099Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import random\n\n# Ensure DataLoader tensors are on the correct device\ndef move_batch_to_device(batch, device):\n    return {key: value.to(device) for key, value in batch.items()}\n\nimport random\ndef train_model(model, train_dl, epochs, display_every=200, log_file=\"logs_training_final.csv\"):\n    # Prepare the CSV file for logging\n    with open(log_file, mode='w', newline='') as file:\n        writer = csv.writer(file)\n        # Write the header\n        writer.writerow([\"Epoch\", \"Iteration\", \"Loss Name\", \"Average Loss\"])\n\n    for e in range(epochs):\n        loss_meter_dict = create_loss_meters()\n        i = 0\n        # Generate a random interval for image visualization for this epoch\n        visualize_every = random.randint(1, 499)\n        for batch_data in tqdm(train_dl):\n            model.setup_input(batch_data)\n            model.optimize()\n            update_losses(model, loss_meter_dict, count=batch_data['L'].size(0))\n            i += 1\n\n            # Log results at fixed intervals\n            if i % display_every == 0:\n                print(f\"\\nEpoch {e+1}/{epochs}\")\n                print(f\"Iteration {i}/{len(train_dl)}\")\n                log_results(loss_meter_dict, log_file, epoch=e + 1, iteration=i)\n\n            # Visualize images at random intervals\n            if i % visualize_every == 0:\n                print(f\"Visualizing at random iteration {i} (interval: {visualize_every})\")\n                # Fetch a new batch of validation data for visualization\n                data = next(iter(val_dl))\n                visualize(model, data, save=True)","metadata":{"_uuid":"83435053-39d5-4ac6-9153-1ae8169b9b8b","_cell_guid":"9f8e2a63-c4ba-492b-812d-19318050ae37","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-12-09T17:56:44.576750Z","iopub.execute_input":"2024-12-09T17:56:44.577027Z","iopub.status.idle":"2024-12-09T17:56:44.595067Z","shell.execute_reply.started":"2024-12-09T17:56:44.577002Z","shell.execute_reply":"2024-12-09T17:56:44.594351Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def build_res_unet(n_input=1, n_output=2, size=256):\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    # First, instantiate the resnet18 model with pretrained weights\n    backbone = resnet18(pretrained=True)\n    # Now pass this instantiated model to create_body\n    body = create_body(backbone, n_in=n_input, cut=-2)\n    net_G = DynamicUnet(body, n_output, (size, size)).to(device)\n    return net_G\n\n\ndef pretrain_generator(net_G, train_dl, opt, criterion, epochs):\n    for e in range(epochs):\n        loss_meter = AverageMeter()\n        for batch_data in tqdm(train_dl):\n            L, ab = batch_data['L'].to(device), batch_data['ab'].to(device)\n            preds = net_G(L)\n            loss = criterion(preds, ab)\n            opt.zero_grad()\n            loss.backward()\n            opt.step()\n            \n            loss_meter.update(loss.item(), L.size(0))\n            \n        print(f\"Epoch {e + 1}/{epochs}\")\n        print(f\"L1 Loss: {loss_meter.avg:.5f}\")","metadata":{"_uuid":"d5b82d2e-2862-400f-9056-4fb0a0a900ed","_cell_guid":"40965407-fade-4f79-8bd8-452edb06dd59","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-12-09T17:56:44.595974Z","iopub.execute_input":"2024-12-09T17:56:44.596247Z","iopub.status.idle":"2024-12-09T17:56:44.607408Z","shell.execute_reply.started":"2024-12-09T17:56:44.596223Z","shell.execute_reply":"2024-12-09T17:56:44.606712Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Pretrain the generator\nnet_G = build_res_unet(n_input=1, n_output=2, size=256)\nopt_g = optim.Adam(net_G.parameters(), lr=1e-4)\ncriterion_L1 = nn.L1Loss()\n\nprint(\"Pretraining the generator with L1 loss...\")\npretrain_generator(net_G, train_dl, opt_g, criterion_L1, epochs=20)\n\n# Save the pretrained generator weights\ntorch.save(net_G.state_dict(), \"res18-unet-v2.pt\")\nprint(\"Pretraining complete and weights saved.\")\n\"\"\"","metadata":{"_uuid":"7511c06b-805e-44d3-82a5-8d4a26b5e3ea","_cell_guid":"c6509ce0-d488-43b1-a97c-9a00bf346e2c","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\"\"\"","metadata":{"_uuid":"58aa54e6-746b-4e20-995c-c19d2ee2d8f2","_cell_guid":"1cf89252-3a1d-4b9d-b41e-8b698ec74714","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-12-08T18:37:20.684974Z","iopub.status.idle":"2024-12-08T18:37:20.685320Z","shell.execute_reply.started":"2024-12-08T18:37:20.685153Z","shell.execute_reply":"2024-12-08T18:37:20.685170Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define the path to the pretrained weights\npretrained_weights_path = \"/kaggle/working/res18-unet.pt\"  # Update this path if the weights are saved elsewhere\n\n# Load the pretrained generator\nprint(\"Loading pretrained generator weights...\")\nnet_G = build_res_unet(n_input=1, n_output=2, size=256)  # Build the generator architecture\nnet_G.load_state_dict(torch.load(pretrained_weights_path, map_location=device))  # Load weights\nnet_G = net_G.to(device)  # Move the model to the appropriate device (GPU/CPU)\nnet_G.eval()  # Set the model to evaluation mode (optional, for inference)\n\nprint(\"Pretrained generator loaded successfully!\")\n\"\"\"","metadata":{"_uuid":"1c21da77-d590-40a4-ab41-96de313ae63c","_cell_guid":"ad2a6a3c-8bae-4231-94c8-4b276bd91f45","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport csv\n# Ensure the images directory exists\n#os.makedirs(\"/kaggle/working/images\", exist_ok=True)\n#!rm /kaggle/working/images/colorization_1733694174.787311.png\n#!mkdir images_new","metadata":{"_uuid":"793e4264-3eb0-46a1-8dc5-40049ddba95b","_cell_guid":"573a00b5-bd8f-47bc-a8a3-1f9037bc3216","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-12-09T17:56:46.799722Z","iopub.execute_input":"2024-12-09T17:56:46.800416Z","iopub.status.idle":"2024-12-09T17:56:46.804272Z","shell.execute_reply.started":"2024-12-09T17:56:46.800384Z","shell.execute_reply":"2024-12-09T17:56:46.803239Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load the pretrained generator from the working directory\nnet_G = build_res_unet(n_input=1, n_output=2, size=256)\n\n# Ensure the model is on the GPU if available\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nnet_G = net_G.to(device)\n\n# Load the pretrained weights into the generator\npretrained_weights_path = \"/kaggle/input/res18-v2/other/default/1/res18-unet-v2.pt\"  # Path to the weights file\nnet_G.load_state_dict(torch.load(pretrained_weights_path, map_location=device))\nprint(\"Pretrained weights loaded into the generator.\")\n\n# Create the main model with the pretrained net_G\nmodel = MainModel(net_G=net_G, lr_G=2e-4, lr_D=2e-4, beta1=0.5, beta2=0.999, lambda_L1=100.)\nmodel = model.to(device)  # Ensure the full model is on the GPU\nprint(\"Main model created and moved to the GPU (if available).\")\n\n# Train the model\nprint(\"Training the full model (GAN + L1) now...\")\ntrain_model(model, train_dl, epochs=50, display_every=200)\nprint(\"Training complete.\")","metadata":{"_uuid":"9cf67405-0d6a-4e56-9555-29f137bc463c","_cell_guid":"be509480-4a4e-4bb3-9f0c-d256cb673c2d","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load the pretrained generator\nnet_G = build_res_unet(n_input=1, n_output=2, size=256)\nnet_G.load_state_dict(torch.load(\"res18-unet.pt\", map_location=device))\n\n# Create the main model with the pretrained net_G\nmodel = MainModel(net_G=net_G, lr_G=2e-4, lr_D=2e-4, beta1=0.5, beta2=0.999, lambda_L1=100.)\nprint(\"Training the full model (GAN + L1) now...\")\ntrain_model(model, train_dl, epochs=50, display_every=200)\nprint(\"Training complete.\")\n\"\"\"","metadata":{"_uuid":"747b7008-8a80-4612-befb-dd7b629bee85","_cell_guid":"e3483759-8420-4b05-8bf3-89b1446ec265","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Save the generator weights\ngenerator_save_path = \"/kaggle/working/net_G_final.pt\"\ntorch.save(model.net_G.state_dict(), generator_save_path)\nprint(f\"Generator weights saved to {generator_save_path}\")\n\n# Save the entire model\nmain_model_save_path = \"/kaggle/working/main_model_final.pt\"\ntorch.save({\n    'net_G': model.net_G.state_dict(),\n    'net_D': model.net_D.state_dict(),\n    'opt_G': model.opt_G.state_dict(),\n    'opt_D': model.opt_D.state_dict()\n}, main_model_save_path)\nprint(f\"Full model saved to {main_model_save_path}\")","metadata":{"_uuid":"ef000374-4a78-4859-b5fe-b7196acefbf9","_cell_guid":"04b5f080-d700-4cfb-b99c-8769c6de2e22","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"_uuid":"80e88f07-da7b-4954-96d4-836522ca17c2","_cell_guid":"ff2dbab0-46fe-4614-b4aa-11be8a715944","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"_uuid":"bbba8e9e-73e2-4517-a99c-cdf9894c1d6d","_cell_guid":"9723fafa-88cc-4d01-87e1-2b07e1788778","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom skimage.metrics import structural_similarity as ssim\nfrom skimage.color import lab2rgb\nimport os\n\n# Ensure the directory for saving plots exists\nos.makedirs(\"predicted_samples\", exist_ok=True)\n\n# Load the generator model\ndef load_model(generator_path, device):\n    net_G = build_res_unet(n_input=1, n_output=2, size=256)  # Ensure consistent architecture\n    net_G.load_state_dict(torch.load(generator_path, map_location=device))\n    net_G.eval()  # Set to evaluation mode\n    return net_G.to(device)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ngenerator_path = \"/kaggle/input/yashvidl/other/default/1/net_G_final.pt\"\ngenerator = load_model(generator_path, device)\n\n# Function to convert LAB to RGB\ndef lab_to_rgb(L, ab):\n    L = (L + 1.) * 50.\n    ab = ab * 110.\n    Lab = np.concatenate([L, ab], axis=1).transpose(0, 2, 3, 1)\n    rgb_imgs = [lab2rgb(img) for img in Lab]\n    return np.stack(rgb_imgs)\n\n# Metrics Calculation\nfrom skimage.metrics import structural_similarity as ssim\nimport numpy as np\n\ndef calculate_metrics(color, predicted):\n    \"\"\"\n    Calculate evaluation metrics: MSE, PSNR, and SSIM with robust handling for small images and explicit channel_axis.\n    \"\"\"\n    try:\n        # Mean Squared Error\n        mse = np.mean((color - predicted) ** 2)\n        \n        # Peak Signal-to-Noise Ratio\n        psnr = 20 * np.log10(1.0 / np.sqrt(mse)) if mse > 0 else float('inf')\n        \n        # Determine minimum dimension of the image\n        min_dim = min(color.shape[0], color.shape[1])\n        \n        # Dynamically set `win_size` or skip SSIM if the image is too small\n        if min_dim < 7:\n            print(f\"Skipping SSIM for image with insufficient dimensions: {color.shape}\")\n            ssim_value = 0.0\n        else:\n            win_size = min(7, min_dim if min_dim % 2 == 1 else min_dim - 1)\n            ssim_value = ssim(color, predicted, data_range=1.0, win_size=win_size, channel_axis=-1)\n        \n        return mse, psnr, ssim_value\n    except Exception as e:\n        print(f\"Error calculating metrics: {e}\")\n        return float('inf'), float('inf'), 0.0\n\n\n\n\n# Visualization\ndef plot_images_with_metrics(color, grayscale, predicted, mse, psnr, ssim_value, sample_idx):\n    try:\n        plt.figure(figsize=(15, 15))\n        plt.subplot(1, 3, 1)\n        plt.title('Color Image', color='green', fontsize=20)\n        plt.imshow(color)\n        plt.axis('off')\n\n        plt.subplot(1, 3, 2)\n        plt.title('Grayscale Image', color='black', fontsize=20)\n        plt.imshow(grayscale, cmap='gray')\n        plt.axis('off')\n\n        plt.subplot(1, 3, 3)\n        plt.title(f'Predicted Image\\nMSE: {mse:.4f}\\nPSNR: {psnr:.2f} dB\\nSSIM: {ssim_value:.4f}', \n                  color='red', fontsize=16)\n        plt.imshow(predicted)\n        plt.axis('off')\n\n        plt.savefig(f'predicted_samples/predicted_sample_{sample_idx}.png', bbox_inches='tight')\n        plt.show()\n    except Exception as e:\n        print(f\"Error plotting images: {e}\")\n\n# Evaluation loop\nresults = []\nfor i, data in enumerate(val_dl):  # Iterate over validation DataLoader\n    if i >= 10:  # Test on first 10 batches (adjust as needed)\n        break\n\n    L = data['L'].to(device)\n    ab_real = data['ab'].to(device)\n\n    # Predict color channels\n    with torch.no_grad():\n        ab_predicted = generator(L).cpu().numpy()\n\n    # Convert to RGB for visualization and metrics\n    predicted_rgb = lab_to_rgb(L.cpu().numpy(), ab_predicted)\n    real_rgb = lab_to_rgb(L.cpu().numpy(), ab_real.cpu().numpy())\n\n    for idx in range(len(L)):\n        real_img = real_rgb[idx]\n        predicted_img = predicted_rgb[idx]\n    \n        print(f\"Processing Image {idx}: Real shape: {real_img.shape}, Predicted shape: {predicted_img.shape}\")\n        \n        # Calculate metrics\n        mse, psnr, ssim_value = calculate_metrics(real_img, predicted_img)\n        print(f\"Metrics for Image {idx}: MSE={mse:.4f}, PSNR={psnr:.2f} dB, SSIM={ssim_value:.4f}\")\n\n    for idx in range(len(L)):\n        # Calculate metrics\n        mse, psnr, ssim_value = calculate_metrics(real_rgb[idx], predicted_rgb[idx])\n        results.append([mse, psnr, ssim_value])\n\n        # Plot and save images with metrics\n        plot_images_with_metrics(\n            real_rgb[idx],\n            L[idx][0].cpu().numpy(),  # Grayscale image\n            predicted_rgb[idx],\n            mse,\n            psnr,\n            ssim_value,\n            sample_idx=i * len(L) + idx\n        )\n\n# Calculate average metrics\nif results:\n    average_metrics = np.mean(results, axis=0)\n    print(f\"Average Metrics: MSE={average_metrics[0]:.4f}, PSNR={average_metrics[1]:.2f} dB, SSIM={average_metrics[2]:.4f}\")\nelse:\n    print(\"No results to average.\")","metadata":{"_uuid":"bcc1fb86-3c16-4cb7-93b7-cc5a3e415ae7","_cell_guid":"820c5217-2cb2-46e0-bc09-15f6d4801b4a","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-12-09T18:20:36.826365Z","iopub.execute_input":"2024-12-09T18:20:36.826725Z","iopub.status.idle":"2024-12-09T18:23:03.399599Z","shell.execute_reply.started":"2024-12-09T18:20:36.826695Z","shell.execute_reply":"2024-12-09T18:23:03.398603Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom matplotlib.backends.backend_pdf import PdfPages\n\n# Sort results by MSE (ascending), PSNR (descending), and SSIM (descending)\nsorted_results = sorted(\n    enumerate(results),  # Include the index to identify which image\n    key=lambda x: (x[1][0], -x[1][1], -x[1][2])  # Sort by MSE (low), then PSNR (high), then SSIM (high)\n)\n\n# Extract the top 100 results\ntop_100_results = sorted_results[:100]\n\n# Create a PDF file to save the plots\noutput_pdf_path = \"/kaggle/working/top_100_predictions.pdf\"\npdf = PdfPages(output_pdf_path)\n\n# Function to add images to the PDF\ndef add_prediction_to_pdf(pdf, real_img, grayscale_img, predicted_img, mse, psnr, ssim_value, rank):\n    \"\"\"\n    Add the ground truth, grayscale input, and predicted image with metrics to a PDF.\n    \"\"\"\n    plt.figure(figsize=(15, 5))\n\n    # Ground Truth Image\n    plt.subplot(1, 3, 1)\n    plt.imshow(real_img)\n    plt.title(\"Ground Truth\", fontsize=14)\n    plt.axis(\"off\")\n\n    # Grayscale Input Image\n    plt.subplot(1, 3, 2)\n    plt.imshow(grayscale_img, cmap=\"gray\")\n    plt.title(\"Grayscale Input\", fontsize=14)\n    plt.axis(\"off\")\n\n    # Predicted Image\n    plt.subplot(1, 3, 3)\n    plt.imshow(predicted_img)\n    plt.title(f\"Prediction\\nMSE: {mse:.4f}, PSNR: {psnr:.2f}, SSIM: {ssim_value:.4f}\", fontsize=12)\n    plt.axis(\"off\")\n\n    plt.suptitle(f\"Rank: {rank}\", fontsize=16, color=\"blue\")\n    plt.tight_layout()\n\n    # Save the current figure to the PDF\n    pdf.savefig()\n    plt.close()\n\n# Add the top 100 predictions to the PDF\nfor rank, (index, metrics) in enumerate(top_100_results, start=1):\n    mse, psnr, ssim_value, *extra_metrics = metrics  # Unpack the first three metrics\n\n    # Retrieve the real image, grayscale input, and predicted image\n    L = val_dl.dataset[index][\"L\"].numpy()  # Grayscale input (normalized)\n    ab_real = val_dl.dataset[index][\"ab\"].numpy()  # Ground truth color\n    ab_predicted = generator(torch.tensor(L).unsqueeze(0).to(device)).cpu().detach().numpy().squeeze()\n\n    # Convert LAB to RGB\n    real_img = lab_to_rgb(L[np.newaxis, ...], ab_real[np.newaxis, ...])[0]\n    predicted_img = lab_to_rgb(L[np.newaxis, ...], ab_predicted[np.newaxis, ...])[0]\n    grayscale_img = L[0]  # Grayscale image for visualization\n\n    # Add the prediction to the PDF\n    add_prediction_to_pdf(pdf, real_img, grayscale_img, predicted_img, mse, psnr, ssim_value, rank)\n\n# Close the PDF file\npdf.close()\n\nprint(f\"PDF saved to: {output_pdf_path}\")","metadata":{"_uuid":"bd9956b5-ac82-4487-814c-5ee23540a828","_cell_guid":"89359c91-2688-4489-9d06-ec472e855965","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-12-09T19:11:45.249693Z","iopub.execute_input":"2024-12-09T19:11:45.250350Z","iopub.status.idle":"2024-12-09T19:12:38.322361Z","shell.execute_reply.started":"2024-12-09T19:11:45.250307Z","shell.execute_reply":"2024-12-09T19:12:38.321389Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom skimage.metrics import structural_similarity as ssim\nfrom skimage.color import lab2rgb\nimport warnings\nfrom scipy.linalg import sqrtm\nfrom torchvision.models import resnet50\nfrom torchvision.transforms import Resize\n\n# Ignore warnings\nwarnings.filterwarnings(\"ignore\")\n\n# Load the generator model\ndef load_model(generator_path, device):\n    net_G = build_res_unet(n_input=1, n_output=2, size=256)  # Ensure consistent architecture\n    net_G.load_state_dict(torch.load(generator_path, map_location=device))\n    net_G.eval()  # Set to evaluation mode\n    return net_G.to(device)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ngenerator_path = \"/kaggle/input/yashvidl/other/default/1/net_G_final.pt\"\ngenerator = load_model(generator_path, device)\n\n# Convert LAB to RGB\ndef lab_to_rgb(L, ab):\n    L = (L + 1.) * 50.\n    ab = ab * 110.\n    Lab = np.concatenate([L, ab], axis=1).transpose(0, 2, 3, 1)\n    rgb_imgs = [lab2rgb(img) for img in Lab]\n    return np.stack(rgb_imgs)\n\n# FID Helper Functions\nfrom scipy.linalg import sqrtm\n\ndef calculate_fid(real_features, fake_features):\n    \"\"\"\n    Calculate FID between real and fake features.\n    \"\"\"\n    # Compute mean and covariance for real and generated features\n    mu1 = np.mean(real_features, axis=0)\n    sigma1 = np.cov(real_features, rowvar=False)\n    mu2 = np.mean(fake_features, axis=0)\n    sigma2 = np.cov(fake_features, rowvar=False)\n    \n    # Compute the mean difference\n    diff = mu1 - mu2\n    diff_squared = diff @ diff\n\n    # Compute the square root of the product of covariance matrices\n    covmean, _ = sqrtm(sigma1 @ sigma2, disp=False)\n\n    # Handle imaginary numbers from sqrtm (they can occur due to numerical instability)\n    if np.iscomplexobj(covmean):\n        covmean = covmean.real\n\n    # Calculate FID\n    fid = diff_squared + np.trace(sigma1 + sigma2 - 2 * covmean)\n    return fid\n\ndef extract_features(images, model, batch_size=32):\n    \"\"\"\n    Extract features using a pre-trained ResNet50 model.\n    \"\"\"\n    features = []\n    transform = Resize((224, 224))  # ResNet50 expects (224, 224) inputs\n    for i in range(0, len(images), batch_size):\n        batch = torch.tensor(images[i:i + batch_size]).permute(0, 3, 1, 2).to(device)  # (B, H, W, C) -> (B, C, H, W)\n        batch = transform(batch)  # Resize to (224, 224)\n        if batch.ndim != 4:\n            print(f\"Invalid batch shape: {batch.shape}. Skipping this batch.\")\n            continue\n        with torch.no_grad():\n            pred = model(batch)\n        features.append(pred.cpu().numpy())\n    return np.concatenate(features, axis=0)\n\n# Metrics Calculation\ndef calculate_metrics(color, predicted):\n    \"\"\"\n    Calculate MSE, PSNR, and SSIM.\n    \"\"\"\n    try:\n        mse = np.mean((color - predicted) ** 2)\n        psnr = 20 * np.log10(1.0 / np.sqrt(mse)) if mse > 0 else float('inf')\n\n        min_dim = min(color.shape[0], color.shape[1])\n        if min_dim < 7:\n            ssim_value = 0.0\n        else:\n            win_size = min(7, min_dim if min_dim % 2 == 1 else min_dim - 1)\n            ssim_value = ssim(color, predicted, data_range=1.0, win_size=win_size, channel_axis=-1)\n\n        return mse, psnr, ssim_value\n    except Exception as e:\n        print(f\"Error calculating metrics: {e}\")\n        return float('inf'), float('inf'), 0.0\n\n# Load ResNet50 for FID\nresnet_model = resnet50(pretrained=True).to(device)\nresnet_model.eval()\n\n# Evaluation Loop\nresults = []  # Store MSE, PSNR, SSIM, FID for all images\nall_mse, all_psnr, all_ssim = [], [], []\nreal_features, fake_features = [], []\n\nfor i, data in enumerate(val_dl):\n    L = data['L'].to(device)\n    ab_real = data['ab'].to(device)\n\n    # Predict color channels\n    with torch.no_grad():\n        ab_predicted = generator(L).cpu().numpy()\n\n    # Convert to RGB\n    predicted_rgb = lab_to_rgb(L.cpu().numpy(), ab_predicted)\n    real_rgb = lab_to_rgb(L.cpu().numpy(), ab_real.cpu().numpy())\n\n    # Collect real and fake features for FID\n    real_features.append(real_rgb)\n    fake_features.append(predicted_rgb)\n\n    for idx in range(len(L)):\n        real_img = real_rgb[idx]\n        predicted_img = predicted_rgb[idx]\n        \n        # Calculate metrics\n        mse, psnr, ssim_value = calculate_metrics(real_img, predicted_img)\n        results.append([mse, psnr, ssim_value])\n        all_mse.append(mse)\n        all_psnr.append(psnr)\n        all_ssim.append(ssim_value)\n\n# FID Calculation\nreal_features_np = np.concatenate(real_features)\nfake_features_np = np.concatenate(fake_features)\n\nreal_features = extract_features(real_features_np, resnet_model)\nfake_features = extract_features(fake_features_np, resnet_model)\n\nfid_value = calculate_fid(real_features, fake_features)\nall_fid = [fid_value] * len(results)\n\n# Add FID to results\nresults = [result + [fid_value] for result in results]\n\n# Calculate average metrics\naverage_metrics = np.mean(results, axis=0)\nprint(f\"Average Metrics: MSE={average_metrics[0]:.4f}, PSNR={average_metrics[1]:.2f} dB, SSIM={average_metrics[2]:.4f}, FID={average_metrics[3]:.4f}\")\n\n# Plotting Metrics\ndef plot_metric(metric_values, metric_name):\n    plt.figure(figsize=(10, 5))\n    plt.plot(metric_values, label=metric_name)\n    plt.xlabel(\"Image Index\")\n    plt.ylabel(metric_name)\n    plt.title(f\"{metric_name} Across Validation Images\")\n    plt.legend()\n    plt.tight_layout()\n    plt.show()\n\n# Separate plots for each metric\nplot_metric(all_mse, \"MSE\")\nplot_metric(all_psnr, \"PSNR (dB)\")\nplot_metric(all_ssim, \"SSIM\")\nplot_metric([fid_value] * len(all_mse), \"FID\")","metadata":{"_uuid":"4ea7a8e7-9d43-4176-a129-7321f5f20645","_cell_guid":"337cc563-01d6-4c2d-8faa-edbab1b14b20","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-12-09T19:00:31.277681Z","iopub.execute_input":"2024-12-09T19:00:31.278424Z","iopub.status.idle":"2024-12-09T19:01:50.246789Z","shell.execute_reply.started":"2024-12-09T19:00:31.278391Z","shell.execute_reply":"2024-12-09T19:01:50.245728Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Calculate average metrics (excluding FID from per-image results)\naverage_metrics = np.mean(results, axis=0)\nprint(f\"Average Metrics: MSE={average_metrics[0]:.4f}, PSNR={average_metrics[1]:.2f} dB, SSIM={average_metrics[2]:.4f}\")\n\n# Print the global FID value\nprint(f\"Global FID: {fid_value:.4f}\")","metadata":{"_uuid":"d2c5e311-73c5-40fa-b078-8bb209b4ce83","_cell_guid":"5f872920-c2ae-4f72-8a3d-583281cb9018","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-12-09T19:01:50.249034Z","iopub.execute_input":"2024-12-09T19:01:50.249918Z","iopub.status.idle":"2024-12-09T19:01:50.256898Z","shell.execute_reply.started":"2024-12-09T19:01:50.249882Z","shell.execute_reply":"2024-12-09T19:01:50.255987Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\n\n# Assuming results is a list of lists: [[mse1, psnr1, ssim1], [mse2, psnr2, ssim2], ...]\nif results:\n    # Convert the results list to a NumPy array for easier manipulation\n    results_array = np.array(results)\n    \n    # Calculate the average along the columns (axis=0)\n    average_metrics = np.mean(results_array, axis=0)\n    \n    # Print the average metrics\n    print(f\"Average Metrics: MSE={average_metrics[0]:.4f}, PSNR={average_metrics[1]:.2f} dB, SSIM={average_metrics[2]:.4f}\")\nelse:\n    print(\"Results list is empty. No metrics to average.\")","metadata":{"_uuid":"84b2e9eb-2231-4aec-ba9e-41ae0ec807b3","_cell_guid":"a31d1951-4626-43eb-addc-3f19e31a34c2","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-12-09T18:27:10.154438Z","iopub.execute_input":"2024-12-09T18:27:10.154790Z","iopub.status.idle":"2024-12-09T18:27:10.160770Z","shell.execute_reply.started":"2024-12-09T18:27:10.154760Z","shell.execute_reply":"2024-12-09T18:27:10.159929Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nfrom pathlib import Path\n\n# Define the paths to the saved model files\nmain_model_path = \"/kaggle/input/yashvidl/other/default/1/main_model_final.pt\"\ngenerator_weights_path = \"/kaggle/input/yashvidl/other/default/1/net_G_final.pt\"\n\n# Ensure the device is set (GPU if available)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Load the generator architecture\ndef build_res_unet(n_input=1, n_output=2, size=256):\n    from fastai.vision.learner import create_body\n    from torchvision.models.resnet import resnet18\n    from fastai.vision.models.unet import DynamicUnet\n    backbone = resnet18(pretrained=False)  # Pretrained=False because we're loading custom weights\n    body = create_body(backbone, n_in=n_input, cut=-2)\n    net_G = DynamicUnet(body, n_output, (size, size)).to(device)\n    return net_G\n\n# Initialize the generator and discriminator\nnet_G = build_res_unet(n_input=1, n_output=2, size=256)\nnet_D = PatchDiscriminator(input_c=3, n_down=3, num_filters=64).to(device)\n\n# Load the saved generator weights\nprint(\"Loading generator weights...\")\nnet_G.load_state_dict(torch.load(generator_weights_path, map_location=device))\nprint(\"Generator weights loaded successfully.\")\n\n# Load the full model state\nprint(\"Loading full model state...\")\ncheckpoint = torch.load(main_model_path, map_location=device)\nnet_G.load_state_dict(checkpoint['net_G'])\nnet_D.load_state_dict(checkpoint['net_D'])\n\n# Load optimizer states if needed\nopt_G = torch.optim.Adam(net_G.parameters(), lr=2e-4, betas=(0.5, 0.999))\nopt_D = torch.optim.Adam(net_D.parameters(), lr=2e-4, betas=(0.5, 0.999))\nopt_G.load_state_dict(checkpoint['opt_G'])\nopt_D.load_state_dict(checkpoint['opt_D'])\n\nprint(\"Full model and optimizers loaded successfully.\")","metadata":{"_uuid":"398cc376-4854-4185-bea8-131c54a7e697","_cell_guid":"894192dd-5935-4a04-81ff-c3c9c8f64988","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-12-09T17:57:16.621583Z","iopub.execute_input":"2024-12-09T17:57:16.622462Z","iopub.status.idle":"2024-12-09T17:57:18.160939Z","shell.execute_reply.started":"2024-12-09T17:57:16.622428Z","shell.execute_reply":"2024-12-09T17:57:18.159942Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class ColorizationDatasetEval(Dataset):\n    def __init__(self, paths, size=256):\n        self.transforms = transforms.Compose([\n            transforms.Resize((size, size), Image.BICUBIC),\n        ])\n        self.size = size\n        self.paths = [path for path in paths if os.path.isfile(path)]  # Filter valid paths\n\n    def __getitem__(self, idx):\n        try:\n            img = Image.open(self.paths[idx]).convert(\"RGB\")\n            img = self.transforms(img)\n            img = np.array(img)\n            img_lab = rgb2lab(img).astype(\"float32\")\n            img_lab = transforms.ToTensor()(img_lab)\n            L = img_lab[[0], ...] / 50. - 1.\n            ab = img_lab[[1, 2], ...] / 110.\n            return {'L': L, 'ab': ab, 'path': self.paths[idx]}\n        except Exception as e:\n            print(f\"Error loading image {self.paths[idx]}: {e}\")\n            return None  # Return None if an image fails to load\n\n    def __len__(self):\n        return len(self.paths)","metadata":{"_uuid":"006c673e-b29a-494f-8c42-13c3ccbe304c","_cell_guid":"2a385dc8-0b7b-4aaa-aed6-f15192441f44","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-12-09T18:01:33.264941Z","iopub.execute_input":"2024-12-09T18:01:33.265403Z","iopub.status.idle":"2024-12-09T18:01:33.272482Z","shell.execute_reply.started":"2024-12-09T18:01:33.265365Z","shell.execute_reply":"2024-12-09T18:01:33.271565Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom skimage.metrics import structural_similarity as ssim\nfrom skimage.color import lab2rgb\nimport warnings\nfrom scipy.linalg import sqrtm\nfrom torchvision.models import resnet50\nfrom torchvision.transforms import Resize\n\n# Ignore warnings\nwarnings.filterwarnings(\"ignore\")\n\n# Load the generator model\ndef load_model(generator_path, device):\n    net_G = build_res_unet(n_input=1, n_output=2, size=256)  # Ensure consistent architecture\n    net_G.load_state_dict(torch.load(generator_path, map_location=device))\n    net_G.eval()  # Set to evaluation mode\n    return net_G.to(device)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ngenerator_path = \"/kaggle/input/yashvidl/other/default/1/net_G_final.pt\"\ngenerator = load_model(generator_path, device)\n\n# Convert LAB to RGB\ndef lab_to_rgb(L, ab):\n    L = (L + 1.) * 50.\n    ab = ab * 110.\n    Lab = np.concatenate([L, ab], axis=1).transpose(0, 2, 3, 1)\n    rgb_imgs = [lab2rgb(img) for img in Lab]\n    return np.stack(rgb_imgs)\n\n# FID Helper Functions\ndef calculate_fid(real_features, fake_features):\n    \"\"\"\n    Calculate FID between real and fake features.\n    \"\"\"\n    mu1, sigma1 = np.mean(real_features, axis=0), np.cov(real_features, rowvar=False)\n    mu2, sigma2 = np.mean(fake_features, axis=0), np.cov(fake_features, rowvar=False)\n\n    diff = mu1 - mu2\n    covmean, _ = sqrtm(sigma1 @ sigma2, disp=False)\n\n    if np.iscomplexobj(covmean):\n        covmean = covmean.real\n\n    fid = diff @ diff + np.trace(sigma1 + sigma2 - 2 * covmean)\n    return fid\n\ndef extract_features(images, model, batch_size=32):\n    \"\"\"\n    Extract features using a pre-trained ResNet50 model.\n    \"\"\"\n    features = []\n    transform = Resize((224, 224))  # ResNet50 expects (224, 224) inputs\n    for i in range(0, len(images), batch_size):\n        batch = torch.tensor(images[i:i + batch_size]).permute(0, 3, 1, 2).to(device)  # (B, H, W, C) -> (B, C, H, W)\n        batch = transform(batch)  # Resize to (224, 224)\n        if batch.ndim != 4:\n            print(f\"Invalid batch shape: {batch.shape}. Skipping this batch.\")\n            continue\n        with torch.no_grad():\n            pred = model(batch)\n        features.append(pred.cpu().numpy())\n    return np.concatenate(features, axis=0)\n\n# Metrics Calculation\ndef calculate_metrics(color, predicted):\n    \"\"\"\n    Calculate MSE, PSNR, and SSIM.\n    \"\"\"\n    try:\n        mse = np.mean((color - predicted) ** 2)\n        psnr = 20 * np.log10(1.0 / np.sqrt(mse)) if mse > 0 else float('inf')\n\n        min_dim = min(color.shape[0], color.shape[1])\n        if min_dim < 7:\n            ssim_value = 0.0\n        else:\n            win_size = min(7, min_dim if min_dim % 2 == 1 else min_dim - 1)\n            ssim_value = ssim(color, predicted, data_range=1.0, win_size=win_size, channel_axis=-1)\n\n        return mse, psnr, ssim_value\n    except Exception as e:\n        print(f\"Error calculating metrics: {e}\")\n        return float('inf'), float('inf'), 0.0\n\n# Load ResNet50 for FID\nresnet_model = resnet50(pretrained=True).to(device)\nresnet_model.eval()\n\n# Evaluation Loop\nresults = []  # Store MSE, PSNR, SSIM, FID for all images\nall_mse, all_psnr, all_ssim = [], [], []\nreal_features, fake_features = [], []\n\nfor i, data in enumerate(val_dl):\n    L = data['L'].to(device)\n    ab_real = data['ab'].to(device)\n\n    # Predict color channels\n    with torch.no_grad():\n        ab_predicted = generator(L).cpu().numpy()\n\n    # Convert to RGB\n    predicted_rgb = lab_to_rgb(L.cpu().numpy(), ab_predicted)\n    real_rgb = lab_to_rgb(L.cpu().numpy(), ab_real.cpu().numpy())\n\n    # Collect real and fake features for FID\n    real_features.append(real_rgb)\n    fake_features.append(predicted_rgb)\n\n    for idx in range(len(L)):\n        real_img = real_rgb[idx]\n        predicted_img = predicted_rgb[idx]\n        \n        # Calculate metrics\n        mse, psnr, ssim_value = calculate_metrics(real_img, predicted_img)\n        results.append([mse, psnr, ssim_value])\n        all_mse.append(mse)\n        all_psnr.append(psnr)\n        all_ssim.append(ssim_value)\n\n# FID Calculation\nreal_features_np = np.concatenate(real_features)\nfake_features_np = np.concatenate(fake_features)\n\nreal_features = extract_features(real_features_np, resnet_model)\nfake_features = extract_features(fake_features_np, resnet_model)\n\nfid_value = calculate_fid(real_features, fake_features)\nall_fid = [fid_value] * len(results)\n\n# Add FID to results\nresults = [result + [fid_value] for result in results]\n\n# Calculate average metrics\naverage_metrics = np.mean(results, axis=0)\nprint(f\"Average Metrics: MSE={average_metrics[0]:.4f}, PSNR={average_metrics[1]:.2f} dB, SSIM={average_metrics[2]:.4f}, FID={average_metrics[3]:.4f}\")\n\n# Plotting Metrics\ndef plot_metric(metric_values, metric_name):\n    plt.figure(figsize=(10, 5))\n    plt.plot(metric_values, label=metric_name)\n    plt.xlabel(\"Image Index\")\n    plt.ylabel(metric_name)\n    plt.title(f\"{metric_name} Across Validation Images\")\n    plt.legend()\n    plt.tight_layout()\n    plt.show()\n\n# Separate plots for each metric\nplot_metric(all_mse, \"MSE\")\nplot_metric(all_psnr, \"PSNR (dB)\")\nplot_metric(all_ssim, \"SSIM\")\nplot_metric([fid_value] * len(all_mse), \"FID\")","metadata":{"_uuid":"247e16f8-c332-4e3b-9a92-9c75579f04d9","_cell_guid":"beb0277c-318b-4289-afb0-93e54e10ae44","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-12-09T18:45:10.082228Z","iopub.execute_input":"2024-12-09T18:45:10.082517Z","iopub.status.idle":"2024-12-09T18:46:26.347619Z","shell.execute_reply.started":"2024-12-09T18:45:10.082488Z","shell.execute_reply":"2024-12-09T18:46:26.346571Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"_uuid":"e691b982-32f1-4efd-a7b2-e7f752dc23af","_cell_guid":"9816110b-308d-4e43-ae33-05569a710b56","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null}]}