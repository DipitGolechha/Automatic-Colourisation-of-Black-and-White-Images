{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":6799,"databundleVersionId":4225553,"sourceType":"competition"}],"dockerImageVersionId":30805,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport glob\nimport time\nimport numpy as np\nfrom PIL import Image\nfrom pathlib import Path\nfrom tqdm.notebook import tqdm\nimport matplotlib.pyplot as plt\nfrom skimage.color import rgb2lab, lab2rgb\nPath.ls = lambda x: list(x.iterdir())\n\nimport torch\nfrom torch import nn, optim\nfrom torchvision import transforms\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision.utils import make_grid\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device:\", device)","metadata":{"_uuid":"5b4b87df-b1a4-4f00-b47a-922459b3326d","_cell_guid":"25e12d27-2cc6-44cb-b1b3-65e1e41bbb8c","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-12-09T11:12:52.075423Z","iopub.execute_input":"2024-12-09T11:12:52.075686Z","iopub.status.idle":"2024-12-09T11:12:56.952591Z","shell.execute_reply.started":"2024-12-09T11:12:52.075660Z","shell.execute_reply":"2024-12-09T11:12:56.951608Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from fastai.vision.learner import create_body\nfrom torchvision.models.resnet import resnet18\nfrom fastai.vision.models.unet import DynamicUnet","metadata":{"_uuid":"5efb7f46-2879-4b4e-aa9a-f78df0709645","_cell_guid":"153d6703-6c83-4488-a45c-e08ae36d30b6","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-12-09T11:12:56.954029Z","iopub.execute_input":"2024-12-09T11:12:56.954434Z","iopub.status.idle":"2024-12-09T11:13:00.488655Z","shell.execute_reply.started":"2024-12-09T11:12:56.954398Z","shell.execute_reply":"2024-12-09T11:13:00.487942Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport glob\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nfrom sklearn.model_selection import train_test_split\n\n# Define the path to the training data\ncolor_path = '/kaggle/input/imagenet-object-localization-challenge/ILSVRC/Data/CLS-LOC/train'\n\n# Get all class directories\nclass_dirs = [d for d in os.listdir(color_path) if os.path.isdir(os.path.join(color_path, d))]\n\nmax_images = 10000\nall_images = []\nnp.random.seed(100)\n\n# Gather up to 1000 images total\nfor class_dir in class_dirs:\n    if len(all_images) >= max_images:\n        break\n    class_path_pattern = os.path.join(color_path, class_dir, '*.JPEG')\n    class_images = glob.glob(class_path_pattern)\n    np.random.shuffle(class_images)  # Shuffle to get a random sample from this class\n    needed = max_images - len(all_images)\n    to_add = class_images[:needed]\n    all_images.extend(to_add)\n\nprint(\"Total images collected:\", len(all_images))\n\n# Split into training and validation sets (80% train, 20% val)\ntrain_paths, val_paths = train_test_split(all_images, test_size=0.2, random_state=123)\n\nprint(\"Total training images:\", len(train_paths))\nprint(\"Total validation images:\", len(val_paths))\n\n# Display a few training images\n_, axes = plt.subplots(4, 4, figsize=(12, 12))\nfor ax, img_path in zip(axes.flatten(), train_paths[:16]):\n    img = Image.open(img_path)\n    ax.imshow(img)\n    ax.axis(\"off\")\nplt.tight_layout()\nplt.show()","metadata":{"_uuid":"afd7ba8a-e838-4787-aa75-534c730886e2","_cell_guid":"08fc2206-1e62-4be9-b945-4561f01a54ef","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-12-09T11:13:00.489579Z","iopub.execute_input":"2024-12-09T11:13:00.489814Z","iopub.status.idle":"2024-12-09T11:13:03.234002Z","shell.execute_reply.started":"2024-12-09T11:13:00.489792Z","shell.execute_reply":"2024-12-09T11:13:03.232932Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"SIZE = 256\n\nclass ColorizationDataset(Dataset):\n    def __init__(self, paths, split='train'):\n        if split == 'train':\n            self.transforms = transforms.Compose([\n                transforms.Resize((SIZE, SIZE), Image.BICUBIC),\n                transforms.RandomHorizontalFlip(),\n            ])\n        else:\n            self.transforms = transforms.Resize((SIZE, SIZE), Image.BICUBIC)\n        \n        self.split = split\n        self.size = SIZE\n        self.paths = paths\n    \n    def __getitem__(self, idx):\n        img = Image.open(self.paths[idx]).convert(\"RGB\")\n        img = self.transforms(img)\n        img = np.array(img)\n        img_lab = rgb2lab(img).astype(\"float32\")\n        img_lab = transforms.ToTensor()(img_lab)\n        L = img_lab[[0], ...] / 50. - 1.\n        ab = img_lab[[1, 2], ...] / 110.\n        return {'L': L, 'ab': ab}\n    \n    def __len__(self):\n        return len(self.paths)\n\ndef make_dataloaders(paths, split='train', batch_size=16, n_workers=4, pin_memory=True):\n    dataset = ColorizationDataset(paths, split=split)\n    dataloader = DataLoader(dataset, batch_size=batch_size, \n                            num_workers=n_workers, pin_memory=pin_memory, shuffle=(split=='train'))\n    return dataloader\n\ntrain_dl = make_dataloaders(train_paths, split='train', batch_size=16)\nval_dl = make_dataloaders(val_paths, split='val', batch_size=16)\n\ndata = next(iter(train_dl))\nLs, abs_ = data['L'], data['ab']\nprint(\"Train batch shapes:\", Ls.shape, abs_.shape)\nprint(\"Number of batches:\", len(train_dl), \"train,\", len(val_dl), \"val\")","metadata":{"_uuid":"89976c0a-069a-45dc-b729-6fe236913565","_cell_guid":"b219f7bc-ca10-456e-a4f7-d6fcca35a1c5","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-12-09T11:13:03.236849Z","iopub.execute_input":"2024-12-09T11:13:03.237142Z","iopub.status.idle":"2024-12-09T11:13:04.431815Z","shell.execute_reply.started":"2024-12-09T11:13:03.237113Z","shell.execute_reply":"2024-12-09T11:13:04.430804Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class UnetBlock(nn.Module):\n    def __init__(self, nf, ni, submodule=None, input_c=None, dropout=False,\n                 innermost=False, outermost=False):\n        super().__init__()\n        self.outermost = outermost\n        if input_c is None: input_c = nf\n        downconv = nn.Conv2d(input_c, ni, kernel_size=4,\n                             stride=2, padding=1, bias=False)\n        downrelu = nn.LeakyReLU(0.2, True)\n        downnorm = nn.BatchNorm2d(ni)\n        uprelu = nn.ReLU(True)\n        upnorm = nn.BatchNorm2d(nf)\n        \n        if outermost:\n            upconv = nn.ConvTranspose2d(ni * 2, nf, kernel_size=4,\n                                        stride=2, padding=1)\n            down = [downconv]\n            up = [uprelu, upconv, nn.Tanh()]\n            model = down + [submodule] + up\n        elif innermost:\n            upconv = nn.ConvTranspose2d(ni, nf, kernel_size=4,\n                                        stride=2, padding=1, bias=False)\n            down = [downrelu, downconv]\n            up = [uprelu, upconv, upnorm]\n            model = down + up\n        else:\n            upconv = nn.ConvTranspose2d(ni * 2, nf, kernel_size=4,\n                                        stride=2, padding=1, bias=False)\n            down = [downrelu, downconv, downnorm]\n            up = [uprelu, upconv, upnorm]\n            if dropout: up += [nn.Dropout(0.5)]\n            model = down + [submodule] + up\n        self.model = nn.Sequential(*model)\n    \n    def forward(self, x):\n        if self.outermost:x\n            return self.model(x)\n        else:\n            return torch.cat([x, self.model(x)], 1)\n\nclass Unet(nn.Module):\n    def __init__(self, input_c=1, output_c=2, n_down=8, num_filters=64):\n        super().__init__()\n        unet_block = UnetBlock(num_filters * 8, num_filters * 8, innermost=True)\n        for _ in range(n_down - 5):\n            unet_block = UnetBlock(num_filters * 8, num_filters * 8, submodule=unet_block, dropout=True)\n        out_filters = num_filters * 8\n        for _ in range(3):\n            unet_block = UnetBlock(out_filters // 2, out_filters, submodule=unet_block)\n            out_filters //= 2\n        self.model = UnetBlock(output_c, out_filters, input_c=input_c, submodule=unet_block, outermost=True)\n    \n    def forward(self, x):\n        return self.model(x)\n\nclass PatchDiscriminator(nn.Module):\n    def __init__(self, input_c, num_filters=64, n_down=3):\n        super().__init__()\n        model = [self.get_layers(input_c, num_filters, norm=False)]\n        model += [self.get_layers(num_filters * 2 ** i, num_filters * 2 ** (i + 1), s=1 if i == (n_down-1) else 2) \n                  for i in range(n_down)]\n        model += [self.get_layers(num_filters * 2 ** n_down, 1, s=1, norm=False, act=False)]\n        self.model = nn.Sequential(*model)\n        \n    def get_layers(self, ni, nf, k=4, s=2, p=1, norm=True, act=True):\n        layers = [nn.Conv2d(ni, nf, k, s, p, bias=not norm)]\n        if norm: layers += [nn.BatchNorm2d(nf)]\n        if act: layers += [nn.LeakyReLU(0.2, True)]\n        return nn.Sequential(*layers)\n    \n    def forward(self, x):\n        return self.model(x)","metadata":{"_uuid":"3f94ec4b-4978-4e82-aaa7-1b25f0689d92","_cell_guid":"32f94e48-5608-4fd7-82a2-53d1a291271f","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-12-09T11:13:04.433188Z","iopub.execute_input":"2024-12-09T11:13:04.433565Z","iopub.status.idle":"2024-12-09T11:13:04.447431Z","shell.execute_reply.started":"2024-12-09T11:13:04.433536Z","shell.execute_reply":"2024-12-09T11:13:04.446597Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class MultiscaleUnet(nn.Module):\n    def __init__(self, input_c=3, output_c=2, n_down=8, num_filters=64):\n        super().__init__()\n        self.unet = Unet(input_c=input_c, output_c=output_c, n_down=n_down, num_filters=num_filters)\n\n    def forward(self, L):\n        # Generate multiscale inputs\n        L_low = nn.functional.interpolate(L, scale_factor=0.5, mode='bilinear', align_corners=False)\n        L_high = nn.functional.interpolate(L, scale_factor=2.0, mode='bilinear', align_corners=False)\n        conditional_input = torch.cat((L, L_low, L_high), dim=1)  # Concatenate original, low, and high-res inputs\n        return self.unet(conditional_input)\n\nclass SelfAttention(nn.Module):\n    def __init__(self, in_dim):\n        super(SelfAttention, self).__init__()\n        self.query = nn.Conv2d(in_dim, in_dim // 8, kernel_size=1)\n        self.key = nn.Conv2d(in_dim, in_dim // 8, kernel_size=1)\n        self.value = nn.Conv2d(in_dim, in_dim, kernel_size=1)\n        self.gamma = nn.Parameter(torch.zeros(1))\n\n    def forward(self, x):\n        batch, channels, height, width = x.size()\n        query = self.query(x).view(batch, -1, width * height).permute(0, 2, 1)\n        key = self.key(x).view(batch, -1, width * height)\n        attention = torch.bmm(query, key)\n        attention = nn.functional.softmax(attention, dim=-1)\n        value = self.value(x).view(batch, -1, width * height)\n        out = torch.bmm(value, attention.permute(0, 2, 1)).view(batch, channels, height, width)\n        out = self.gamma * out + x\n        return out\n\nclass ConditionalUnetWithFeatures(nn.Module):\n    def __init__(self, input_c=1, output_c=2, n_down=8, num_filters=64, feature_dim=512):\n        super().__init__()\n        # ResNet for feature extraction\n        self.feature_extractor = torchvision.models.resnet18(pretrained=True)\n        self.feature_extractor.fc = nn.Identity()  # Remove classification head\n        self.feature_extractor.eval()\n        for param in self.feature_extractor.parameters():\n            param.requires_grad = False\n\n        # Generator with multiscale inputs\n        self.unet = MultiscaleUnet(input_c=input_c + 3, output_c=output_c, n_down=n_down, num_filters=num_filters)\n\n    def forward(self, L):\n        # Extract semantic features\n        with torch.no_grad():\n            features = self.feature_extractor(L.repeat(1, 3, 1, 1))  # Pass grayscale image through ResNet\n        features = features.unsqueeze(-1).unsqueeze(-1).repeat(1, 1, SIZE, SIZE)  # Reshape to spatial dimensions\n        conditional_input = torch.cat((L, features), dim=1)  # Concatenate grayscale and features\n        return self.unet(conditional_input)\n\nclass ConditionalDiscriminatorWithFeatures(PatchDiscriminator):\n    def __init__(self, input_c=3, feature_dim=512, num_filters=64, n_down=3):\n        super().__init__(input_c + feature_dim // 64, num_filters, n_down)\n        self.feature_extractor = torchvision.models.resnet18(pretrained=True)\n        self.feature_extractor.fc = nn.Identity()\n        self.feature_extractor.eval()\n        for param in self.feature_extractor.parameters():\n            param.requires_grad = False\n\n    def forward(self, x, L):\n        # Extract features\n        with torch.no_grad():\n            features = self.feature_extractor(L.repeat(1, 3, 1, 1))\n        features = features.unsqueeze(-1).unsqueeze(-1).repeat(1, 1, SIZE, SIZE)\n        conditional_input = torch.cat((x, features), dim=1)  # Concatenate image and features\n        return super().forward(conditional_input)","metadata":{"_uuid":"4af277cc-b47b-43ba-a4c5-8fa0d6fdd218","_cell_guid":"e33e3675-eaad-4376-9438-0b4d076b4db2","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-12-09T11:13:04.448700Z","iopub.execute_input":"2024-12-09T11:13:04.449060Z","iopub.status.idle":"2024-12-09T11:13:04.464958Z","shell.execute_reply.started":"2024-12-09T11:13:04.449023Z","shell.execute_reply":"2024-12-09T11:13:04.464221Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class GANLoss(nn.Module):\n    def __init__(self, gan_mode='vanilla', real_label=1.0, fake_label=0.0):\n        super().__init__()\n        self.register_buffer('real_label', torch.tensor(real_label))\n        self.register_buffer('fake_label', torch.tensor(fake_label))\n        if gan_mode == 'vanilla':\n            self.loss = nn.BCEWithLogitsLoss()\n        elif gan_mode == 'lsgan':\n            self.loss = nn.MSELoss()\n    \n    def get_labels(self, preds, target_is_real):\n        if target_is_real:\n            labels = self.real_label\n        else:\n            labels = self.fake_label\n        return labels.expand_as(preds)\n    \n    def forward(self, preds, target_is_real):\n        labels = self.get_labels(preds, target_is_real)\n        loss = self.loss(preds, labels)\n        return loss\n\ndef init_weights(net, init='norm', gain=0.02):\n    def init_func(m):\n        classname = m.__class__.__name__\n        if hasattr(m, 'weight') and 'Conv' in classname:\n            if init == 'norm':\n                nn.init.normal_(m.weight.data, mean=0.0, std=gain)\n            elif init == 'xavier':\n                nn.init.xavier_normal_(m.weight.data, gain=gain)\n            elif init == 'kaiming':\n                nn.init.kaiming_normal_(m.weight.data, a=0, mode='fan_in')\n            \n            if hasattr(m, 'bias') and m.bias is not None:\n                nn.init.constant_(m.bias.data, 0.0)\n        elif 'BatchNorm2d' in classname:\n            nn.init.normal_(m.weight.data, 1., gain)\n            nn.init.constant_(m.bias.data, 0.)\n            \n    net.apply(init_func)\n    print(f\"model initialized with {init} initialization\")\n    return net\n\ndef init_model(model, device):\n    model = model.to(device)\n    model = init_weights(model)\n    return model\n\nclass AverageMeter:\n    def __init__(self):\n        self.reset()\n        \n    def reset(self):\n        self.count, self.avg, self.sum = [0.] * 3\n    \n    def update(self, val, count=1):\n        self.count += count\n        self.sum += count * val\n        self.avg = self.sum / self.count\n\ndef create_loss_meters():\n    loss_D_fake = AverageMeter()\n    loss_D_real = AverageMeter()\n    loss_D = AverageMeter()\n    loss_G_GAN = AverageMeter()\n    loss_G_L1 = AverageMeter()\n    loss_G = AverageMeter()\n    \n    return {'loss_D_fake': loss_D_fake,\n            'loss_D_real': loss_D_real,\n            'loss_D': loss_D,\n            'loss_G_GAN': loss_G_GAN,\n            'loss_G_L1': loss_G_L1,\n            'loss_G': loss_G}\n\ndef update_losses(model, loss_meter_dict, count):\n    for loss_name, loss_meter in loss_meter_dict.items():\n        loss = getattr(model, loss_name)\n        loss_meter.update(loss.item(), count=count)","metadata":{"_uuid":"f6018233-9ae4-4469-b600-67a5ae860a3a","_cell_guid":"d401f049-f0a2-4c59-a033-ab46e941caa5","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-12-09T11:13:04.465950Z","iopub.execute_input":"2024-12-09T11:13:04.466232Z","iopub.status.idle":"2024-12-09T11:13:04.484942Z","shell.execute_reply.started":"2024-12-09T11:13:04.466208Z","shell.execute_reply":"2024-12-09T11:13:04.484124Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def lab_to_rgb(L, ab):\n    L = (L + 1.) * 50.\n    ab = ab * 110.\n    Lab = torch.cat([L, ab], dim=1).permute(0, 2, 3, 1).cpu().numpy()\n    rgb_imgs = []\n    for img in Lab:\n        img_rgb = lab2rgb(img)\n        rgb_imgs.append(img_rgb)\n    return np.stack(rgb_imgs, axis=0)\n    \ndef visualize(model, data, save=True):\n    model.net_G.eval()\n    with torch.no_grad():\n        model.setup_input(data)\n        model.forward()\n    model.net_G.train()\n    fake_color = model.fake_color.detach()\n    real_color = model.ab\n    L = model.L\n    fake_imgs = lab_to_rgb(L, fake_color)\n    real_imgs = lab_to_rgb(L, real_color)\n    fig = plt.figure(figsize=(15, 12))  # Adjusted height for row titles\n    rows, cols = 3, 5  # 3 rows (Grayscale, Model generated, Actual), up to 5 columns\n\n    # Add row titles\n    plt.subplot(rows, cols, 1).set_title(\"Grayscale Image\", fontsize=16, loc='left')\n    plt.subplot(rows, cols, cols + 1).set_title(\"Model Generated Image\", fontsize=16, loc='left')\n    plt.subplot(rows, cols, 2 * cols + 1).set_title(\"Actual Image\", fontsize=16, loc='left')\n\n    for i in range(min(5, L.size(0))):\n        # Grayscale Image (Row 1)\n        ax = plt.subplot(rows, cols, i + 1)\n        ax.imshow(L[i][0].cpu(), cmap='gray')\n        ax.axis(\"off\")\n\n        # Model Generated Image (Row 2)\n        ax = plt.subplot(rows, cols, i + 1 + cols)\n        ax.imshow(fake_imgs[i])\n        ax.axis(\"off\")\n\n        # Actual Image (Row 3)\n        ax = plt.subplot(rows, cols, i + 1 + 2 * cols)\n        ax.imshow(real_imgs[i])\n        ax.axis(\"off\")\n\n    plt.tight_layout()\n    plt.show()\n    if save:\n        fig.savefig(f\"images_new/colorization_{time.time()}.png\")\n\ndef log_results(loss_meter_dict, log_file, epoch, iteration):\n    \"\"\"\n    Log the training results to a CSV file and print them to the console.\n    \"\"\"\n    with open(log_file, mode='a', newline='') as file:\n        writer = csv.writer(file)\n        for loss_name, loss_meter in loss_meter_dict.items():\n            print(f\"{loss_name}: {loss_meter.avg:.5f}\")  # Print to console\n            # Append the results to the CSV file\n            writer.writerow([epoch, iteration, loss_name, loss_meter.avg])","metadata":{"_uuid":"c30a606c-fa15-4458-ab38-706a1894d8eb","_cell_guid":"4e7b09de-f9a9-4470-bf5e-bc45e25f8db8","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-12-09T12:41:48.583035Z","iopub.execute_input":"2024-12-09T12:41:48.583874Z","iopub.status.idle":"2024-12-09T12:41:48.594563Z","shell.execute_reply.started":"2024-12-09T12:41:48.583838Z","shell.execute_reply":"2024-12-09T12:41:48.593663Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class ConditionalGANModel(nn.Module):\n    def __init__(self, net_G=None, lr_G=2e-4, lr_D=2e-4, beta1=0.5, beta2=0.999, lambda_L1=100.):\n        super().__init__()\n        \n        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n        self.lambda_L1 = lambda_L1\n        \n        # Initialize or use the provided generator\n        if net_G is None:\n            self.net_G = init_model(Unet(input_c=1, output_c=2, n_down=8, num_filters=64), self.device)\n        else:\n            self.net_G = net_G.to(self.device)\n        \n        # Initialize the discriminator with conditioning\n        self.net_D = init_model(PatchDiscriminator(input_c=3, n_down=3, num_filters=64), self.device)\n        \n        # Define losses\n        self.GANcriterion = GANLoss(gan_mode='vanilla').to(self.device)\n        self.L1criterion = nn.L1Loss()\n        \n        # Optimizers for generator and discriminator\n        self.opt_G = optim.Adam(self.net_G.parameters(), lr=lr_G, betas=(beta1, beta2))\n        self.opt_D = optim.Adam(self.net_D.parameters(), lr=lr_D, betas=(beta1, beta2))\n    \n    def set_requires_grad(self, model, requires_grad=True):\n        for p in model.parameters():\n            p.requires_grad = requires_grad\n        \n    def setup_input(self, data):\n        self.L = data['L'].to(self.device)\n        self.ab = data['ab'].to(self.device)\n        \n    def forward(self):\n        self.fake_color = self.net_G(self.L)\n    \n    def backward_D(self):\n        # Concatenate grayscale input (L) with fake/generated colors\n        fake_image = torch.cat([self.L, self.fake_color], dim=1)\n        fake_preds = self.net_D(fake_image.detach())\n        self.loss_D_fake = self.GANcriterion(fake_preds, False)\n        \n        # Concatenate grayscale input (L) with real colors\n        real_image = torch.cat([self.L, self.ab], dim=1)\n        real_preds = self.net_D(real_image)\n        self.loss_D_real = self.GANcriterion(real_preds, True)\n        \n        # Total discriminator loss\n        self.loss_D = (self.loss_D_fake + self.loss_D_real) * 0.5\n        self.loss_D.backward()\n    \n    def backward_G(self):\n        fake_image = torch.cat([self.L, self.fake_color], dim=1)\n        fake_preds = self.net_D(fake_image)\n        self.loss_G_GAN = self.GANcriterion(fake_preds, True)\n        \n        # L1 loss between the generated and actual colors\n        self.loss_G_L1 = self.L1criterion(self.fake_color, self.ab) * self.lambda_L1\n        \n        # Total generator loss\n        self.loss_G = self.loss_G_GAN + self.loss_G_L1\n        self.loss_G.backward()\n    \n    def optimize(self):\n        # Update discriminator\n        self.forward()\n        self.net_D.train()\n        self.set_requires_grad(self.net_D, True)\n        self.opt_D.zero_grad()\n        self.backward_D()\n        self.opt_D.step()\n        \n        # Update generator\n        self.net_G.train()\n        self.set_requires_grad(self.net_D, False)\n        self.opt_G.zero_grad()\n        self.backward_G()\n        self.opt_G.step()","metadata":{"_uuid":"ca93686c-3a61-4072-9cc3-c2acaba09812","_cell_guid":"4d72d8d1-a7d8-43f4-86a0-ad58f9d208b5","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-12-09T12:30:16.554712Z","iopub.execute_input":"2024-12-09T12:30:16.555073Z","iopub.status.idle":"2024-12-09T12:30:16.567863Z","shell.execute_reply.started":"2024-12-09T12:30:16.555043Z","shell.execute_reply":"2024-12-09T12:30:16.566899Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import random\n\n# Ensure DataLoader tensors are on the correct device\ndef move_batch_to_device(batch, device):\n    return {key: value.to(device) for key, value in batch.items()}\n\nimport random\ndef train_model(model, train_dl, epochs, display_every=200, log_file=\"logs_training_final.csv\"):\n    # Prepare the CSV file for logging\n    with open(log_file, mode='w', newline='') as file:\n        writer = csv.writer(file)\n        # Write the header\n        writer.writerow([\"Epoch\", \"Iteration\", \"Loss Name\", \"Average Loss\"])\n\n    for e in range(epochs):\n        loss_meter_dict = create_loss_meters()\n        i = 0\n        # Generate a random interval for image visualization for this epoch\n        visualize_every = random.randint(1, 499)\n        for batch_data in tqdm(train_dl):\n            model.setup_input(batch_data)\n            model.optimize()\n            update_losses(model, loss_meter_dict, count=batch_data['L'].size(0))\n            i += 1\n\n            # Log results at fixed intervals\n            if i % display_every == 0:\n                print(f\"\\nEpoch {e+1}/{epochs}\")\n                print(f\"Iteration {i}/{len(train_dl)}\")\n                log_results(loss_meter_dict, log_file, epoch=e + 1, iteration=i)\n\n            # Visualize images at random intervals\n            if i % visualize_every == 0:\n                print(f\"Visualizing at random iteration {i} (interval: {visualize_every})\")\n                # Fetch a new batch of validation data for visualization\n                data = next(iter(val_dl))\n                visualize(model, data, save=True)","metadata":{"_uuid":"96b7a9a9-1d27-4d1c-9564-c4828ef523c4","_cell_guid":"c687d1d6-18df-4224-8140-4d811cded0f6","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-12-09T11:13:04.516791Z","iopub.execute_input":"2024-12-09T11:13:04.517049Z","iopub.status.idle":"2024-12-09T11:13:04.526484Z","shell.execute_reply.started":"2024-12-09T11:13:04.517021Z","shell.execute_reply":"2024-12-09T11:13:04.525699Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def build_res_unet(n_input=1, n_output=2, size=256):\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    # First, instantiate the resnet18 model with pretrained weights\n    backbone = resnet18(pretrained=True)\n    # Now pass this instantiated model to create_body\n    body = create_body(backbone, n_in=n_input, cut=-2)\n    net_G = DynamicUnet(body, n_output, (size, size)).to(device)\n    return net_G\n\n\ndef pretrain_generator(net_G, train_dl, opt, criterion, epochs):\n    for e in range(epochs):\n        loss_meter = AverageMeter()\n        for batch_data in tqdm(train_dl):\n            L, ab = batch_data['L'].to(device), batch_data['ab'].to(device)\n            preds = net_G(L)\n            loss = criterion(preds, ab)\n            opt.zero_grad()\n            loss.backward()\n            opt.step()\n            \n            loss_meter.update(loss.item(), L.size(0))\n            \n        print(f\"Epoch {e + 1}/{epochs}\")\n        print(f\"L1 Loss: {loss_meter.avg:.5f}\")","metadata":{"_uuid":"d6242553-6af2-4512-a422-dd4fc3344db5","_cell_guid":"7cf2c626-189d-46b4-ada5-d8eb10832e80","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-12-09T11:13:04.527213Z","iopub.execute_input":"2024-12-09T11:13:04.527478Z","iopub.status.idle":"2024-12-09T11:13:04.539542Z","shell.execute_reply.started":"2024-12-09T11:13:04.527453Z","shell.execute_reply":"2024-12-09T11:13:04.538769Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Pretrain the generator\nnet_G = build_res_unet(n_input=1, n_output=2, size=256)\nopt_g = optim.Adam(net_G.parameters(), lr=1e-4)\ncriterion_L1 = nn.L1Loss()\n\nprint(\"Pretraining the generator with L1 loss...\")\npretrain_generator(net_G, train_dl, opt_g, criterion_L1, epochs=20)\n\n# Save the pretrained generator weights\ntorch.save(net_G.state_dict(), \"res18-unet-v2.pt\")\nprint(\"Pretraining complete and weights saved.\")","metadata":{"_uuid":"8f6166ed-fb77-4ed7-9a4e-285db3bd83c4","_cell_guid":"018c527f-2888-45ee-9886-3dd9342c7d1a","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-12-09T11:13:04.540571Z","iopub.execute_input":"2024-12-09T11:13:04.540908Z","iopub.status.idle":"2024-12-09T12:07:29.712892Z","shell.execute_reply.started":"2024-12-09T11:13:04.540873Z","shell.execute_reply":"2024-12-09T12:07:29.711883Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\"\"\"\n# Define the path to the pretrained weights\npretrained_weights_path = \"/kaggle/working/res18-unet.pt\"  # Update this path if the weights are saved elsewhere\n\n# Load the pretrained generator\nprint(\"Loading pretrained generator weights...\")\nnet_G = build_res_unet(n_input=1, n_output=2, size=256)  # Build the generator architecture\nnet_G.load_state_dict(torch.load(pretrained_weights_path, map_location=device))  # Load weights\nnet_G = net_G.to(device)  # Move the model to the appropriate device (GPU/CPU)\nnet_G.eval()  # Set the model to evaluation mode (optional, for inference)\n\nprint(\"Pretrained generator loaded successfully!\")\n\"\"\"","metadata":{"_uuid":"3a5dc996-7140-4ba8-a702-8cd623c2b00f","_cell_guid":"439ac908-8ffe-4a9d-962b-20445e0b780e","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport csv\n# Ensure the images directory exists\n#os.makedirs(\"/kaggle/working/images\", exist_ok=True)\n#!rm /kaggle/working/images/colorization_1733694174.787311.png\n!mkdir images_new","metadata":{"_uuid":"8aafb918-dc0c-44f1-ac7f-f7e7046351bf","_cell_guid":"3afa8344-c049-464b-9430-a7323629cfc4","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-12-09T12:07:29.719138Z","iopub.execute_input":"2024-12-09T12:07:29.719759Z","iopub.status.idle":"2024-12-09T12:07:30.765284Z","shell.execute_reply.started":"2024-12-09T12:07:29.719717Z","shell.execute_reply":"2024-12-09T12:07:30.764054Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\"\"\"\n# Load the pretrained generator from the working directory\nnet_G = build_res_unet(n_input=1, n_output=2, size=256)\n\n# Ensure the model is on the GPU if available\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nnet_G = net_G.to(device)\n\n# Load the pretrained weights into the generator\npretrained_weights_path = \"/kaggle/input/res18-v2/other/default/1/res18-unet-v2.pt\"  # Path to the weights file\nnet_G.load_state_dict(torch.load(pretrained_weights_path, map_location=device))\nprint(\"Pretrained weights loaded into the generator.\")\n\n# Create the main model with the pretrained net_G\nmodel = MainModel(net_G=net_G, lr_G=2e-4, lr_D=2e-4, beta1=0.5, beta2=0.999, lambda_L1=100.)\nmodel = model.to(device)  # Ensure the full model is on the GPU\nprint(\"Main model created and moved to the GPU (if available).\")\n\n# Train the model\nprint(\"Training the full model (GAN + L1) now...\")\ntrain_model(model, train_dl, epochs=50, display_every=200)\nprint(\"Training complete.\")\n\"\"\"","metadata":{"_uuid":"d1e1a67c-d68e-4cfc-8c37-1261530ca64b","_cell_guid":"f630b236-9239-4290-b2aa-7990d9ae1e40","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-12-09T11:07:43.858130Z","iopub.status.idle":"2024-12-09T11:07:43.858428Z","shell.execute_reply.started":"2024-12-09T11:07:43.858286Z","shell.execute_reply":"2024-12-09T11:07:43.858301Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load the pretrained generator\nnet_G = build_res_unet(n_input=1, n_output=2, size=256)\nnet_G.load_state_dict(torch.load(\"/kaggle/working/res18-unet-v2.pt\", map_location=device))\n\n# Create the main model with the pretrained net_G\nmodel = ConditionalGANModel(net_G=net_G, lr_G=2e-4, lr_D=2e-4, beta1=0.5, beta2=0.999, lambda_L1=100.)\nprint(\"Training the full model (GAN + L1) now...\")\ntrain_model(model, train_dl, epochs=50, display_every=200)\nprint(\"Training complete.\")","metadata":{"_uuid":"d107f5b8-7c2a-4cc8-becf-2a1b781546a7","_cell_guid":"0c8025f7-4c9a-4f95-8960-125b46fafed1","trusted":true,"execution":{"iopub.status.busy":"2024-12-09T12:41:58.171201Z","iopub.execute_input":"2024-12-09T12:41:58.172124Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Save the generator weights\ngenerator_save_path = \"/kaggle/working/net_G_final.pt\"\ntorch.save(model.net_G.state_dict(), generator_save_path)\nprint(f\"Generator weights saved to {generator_save_path}\")\n\n# Save the entire model\nmain_model_save_path = \"/kaggle/working/main_model_final.pt\"\ntorch.save({\n    'net_G': model.net_G.state_dict(),\n    'net_D': model.net_D.state_dict(),\n    'opt_G': model.opt_G.state_dict(),\n    'opt_D': model.opt_D.state_dict()\n}, main_model_save_path)\nprint(f\"Full model saved to {main_model_save_path}\")","metadata":{"_uuid":"66d72d7b-b35b-4e30-898f-eb3d739cdaf0","_cell_guid":"ed232bb2-21e0-4cce-9b6d-deeda6625bb8","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\nfrom skimage.color import lab2rgb\n\ndef lab_to_rgb(L, ab):\n    \"\"\"\n    Convert L and ab channels to RGB images.\n    Args:\n        L: Lightness channel (normalized to [-1, 1])\n        ab: Color channels (normalized to [-1, 1])\n    Returns:\n        RGB image\n    \"\"\"\n    L = (L + 1.) * 50.  # Rescale L to [0, 100]\n    ab = ab * 110.      # Rescale ab to [-110, 110]\n    Lab = np.concatenate([L, ab], axis=0).transpose(1, 2, 0)  # Combine channels\n    return lab2rgb(Lab)\n\ndef plot_results(original_images, grayscale_images, generated_images, num_images=10):\n    \"\"\"\n    Display original, grayscale, and generated images side by side.\n    Args:\n        original_images: List or array of original color images.\n        grayscale_images: List or array of grayscale images.\n        generated_images: List or array of generated colorized images.\n        num_images: Number of images to display.\n    \"\"\"\n    plt.figure(figsize=(15, 5 * num_images))\n    for i in range(num_images):\n        original = original_images[i]\n        grayscale = grayscale_images[i]\n        generated = generated_images[i]\n\n        # Plot original image\n        plt.subplot(num_images, 3, i * 3 + 1)\n        plt.imshow(original)\n        plt.title(\"Original Image\")\n        plt.axis(\"off\")\n\n        # Plot grayscale image\n        plt.subplot(num_images, 3, i * 3 + 2)\n        plt.imshow(grayscale[0], cmap=\"gray\")\n        plt.title(\"Grayscale Image\")\n        plt.axis(\"off\")\n\n        # Plot generated image\n        plt.subplot(num_images, 3, i * 3 + 3)\n        plt.imshow(generated)\n        plt.title(\"Generated Image\")\n        plt.axis(\"off\")\n    plt.tight_layout()\n    plt.show()\n\n# Example usage\n# Assume `original_images` are in RGB, `grayscale_images` are single-channel, and `predicted_images` are the model outputs.\n# Convert predictions from LAB to RGB before displaying.\n\n# Placeholder for 10 original images, grayscale inputs, and generated predictions\noriginal_images = [lab_to_rgb(data['L'][i].cpu().numpy(), data['ab'][i].cpu().numpy()) for i in range(10)]\ngrayscale_images = [data['L'][i].cpu().numpy() for i in range(10)]\ngenerated_images = [lab_to_rgb(data['L'][i].cpu().numpy(), model.fake_color[i].detach().cpu().numpy()) for i in range(10)]\n\n# Display results\nplot_results(original_images, grayscale_images, generated_images, num_images=10)","metadata":{"_uuid":"e5b24a42-5eed-4e66-912c-8f36372c03e3","_cell_guid":"656b4b9a-b82f-43b6-91da-1e69e3cad02a","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.model_selection import KFold\nfrom torch.utils.data import Subset, DataLoader\nimport copy\n\ndef cross_validate(model_class, dataset, k_folds=5, epochs=10, batch_size=16, lr=1e-4, lambda_L1=100.):\n    \"\"\"\n    Perform K-fold cross-validation for the given model and dataset.\n\n    Args:\n        model_class: The model class to be instantiated for each fold.\n        dataset: The dataset to split into K folds.\n        k_folds: Number of folds for cross-validation.\n        epochs: Number of epochs to train each fold.\n        batch_size: Batch size for DataLoader.\n        lr: Learning rate for optimizer.\n        lambda_L1: Weight for L1 loss in generator.\n\n    Returns:\n        Average loss and metrics over all folds.\n    \"\"\"\n    kfold = KFold(n_splits=k_folds, shuffle=True, random_state=123)\n    fold_results = []\n\n    # Split dataset into K folds\n    for fold, (train_idx, val_idx) in enumerate(kfold.split(dataset)):\n        print(f\"\\nFold {fold + 1}/{k_folds}\")\n\n        # Create dataloaders for this fold\n        train_subset = Subset(dataset, train_idx)\n        val_subset = Subset(dataset, val_idx)\n        train_dl = DataLoader(train_subset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n        val_dl = DataLoader(val_subset, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n\n        # Initialize model\n        model = model_class(lr_G=lr, lambda_L1=lambda_L1)\n        model = model.to(device)\n\n        # Train the model\n        for epoch in range(epochs):\n            model.train()\n            for batch_data in train_dl:\n                model.setup_input(batch_data)\n                model.optimize()\n\n            # Validate the model\n            model.eval()\n            val_loss_meter = AverageMeter()\n            with torch.no_grad():\n                for batch_data in val_dl:\n                    model.setup_input(batch_data)\n                    model.forward()\n                    val_loss = model.L1criterion(model.fake_color, model.ab)\n                    val_loss_meter.update(val_loss.item(), batch_data['L'].size(0))\n\n            print(f\"Fold {fold + 1}, Epoch {epoch + 1}/{epochs}, Validation L1 Loss: {val_loss_meter.avg:.5f}\")\n\n        # Store results for this fold\n        fold_results.append(val_loss_meter.avg)\n\n    # Compute average loss across all folds\n    avg_loss = np.mean(fold_results)\n    print(f\"\\nCross-validation complete. Average Validation L1 Loss: {avg_loss:.5f}\")\n    return avg_loss","metadata":{"_uuid":"d9396879-17c9-44c7-a6ab-7dd2ef3b4be2","_cell_guid":"f9c149d5-8ca5-49eb-9211-1b8f081da4a5","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Instantiate the dataset\ndataset = ColorizationDataset(paths=train_paths, split='train')\n\n# Perform cross-validation\navg_loss = cross_validate(\n    model_class=MainModel,\n    dataset=dataset,\n    k_folds=5,         # 5-fold cross-validation\n    epochs=10,         # 10 epochs per fold\n    batch_size=16,     # Batch size\n    lr=1e-4,           # Learning rate\n    lambda_L1=100.     # L1 loss weight\n)\n\nprint(f\"Final Cross-Validation Average Loss: {avg_loss:.5f}\")","metadata":{"_uuid":"d64a7122-22e0-4017-a4e6-0d3be4df9f6a","_cell_guid":"46af37bb-190a-40cb-9e71-71ebfab754d4","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"_uuid":"94863a3f-9732-4d00-aa66-fe5116386d89","_cell_guid":"99a527b9-81b5-4551-af6f-30604103c5a1","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"_uuid":"a3355477-9c07-4b63-bdd2-a99256635016","_cell_guid":"cdcb4a93-c99b-44e1-986d-c3fdfc6c727d","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null}]}